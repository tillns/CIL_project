Model: "till_model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
padder (Padder)              (None, 128, 128, 1)       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 64, 64, 4)         36        
_________________________________________________________________
batch_normalization_v2 (Batc (None, 64, 64, 4)         16        
_________________________________________________________________
leaky_re_lu (LeakyReLU)      (None, 64, 64, 4)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 64, 64, 4)         144       
_________________________________________________________________
batch_normalization_v2_1 (Ba (None, 64, 64, 4)         16        
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 4)         0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 8)         288       
_________________________________________________________________
batch_normalization_v2_2 (Ba (None, 32, 32, 8)         32        
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 8)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 32, 32, 8)         576       
_________________________________________________________________
batch_normalization_v2_3 (Ba (None, 32, 32, 8)         32        
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 8)         0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 16, 16, 16)        1152      
_________________________________________________________________
batch_normalization_v2_4 (Ba (None, 16, 16, 16)        64        
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 16)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 16, 16, 16)        2304      
_________________________________________________________________
batch_normalization_v2_5 (Ba (None, 16, 16, 16)        64        
_________________________________________________________________
leaky_re_lu_5 (LeakyReLU)    (None, 16, 16, 16)        0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 8, 8, 32)          4608      
_________________________________________________________________
batch_normalization_v2_6 (Ba (None, 8, 8, 32)          128       
_________________________________________________________________
leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 8, 8, 32)          9216      
_________________________________________________________________
batch_normalization_v2_7 (Ba (None, 8, 8, 32)          128       
_________________________________________________________________
leaky_re_lu_7 (LeakyReLU)    (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 4, 4, 32)          9216      
_________________________________________________________________
batch_normalization_v2_8 (Ba (None, 4, 4, 32)          128       
_________________________________________________________________
leaky_re_lu_8 (LeakyReLU)    (None, 4, 4, 32)          0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 4, 4, 32)          9216      
_________________________________________________________________
batch_normalization_v2_9 (Ba (None, 4, 4, 32)          128       
_________________________________________________________________
leaky_re_lu_9 (LeakyReLU)    (None, 4, 4, 32)          0         
_________________________________________________________________
flatten (Flatten)            (None, 512)               0         
_________________________________________________________________
dense (Dense)                (None, 32)                16384     
_________________________________________________________________
batch_normalization_v2_10 (B (None, 32)                128       
_________________________________________________________________
leaky_re_lu_10 (LeakyReLU)   (None, 32)                0         
_________________________________________________________________
dropout (Dropout)            (None, 32)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 32        
_________________________________________________________________
sigmoid_layer (SigmoidLayer) (None, 1)                 0         
_________________________________________________________________
factor_layer (FactorLayer)   (None, 1)                 0         
=================================================================
Total params: 54,036
Trainable params: 53,604
Non-trainable params: 432
_________________________________________________________________

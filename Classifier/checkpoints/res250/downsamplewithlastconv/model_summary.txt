Model: "till_model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 250, 250, 8)       72        
_________________________________________________________________
batch_normalization_v2 (Batc (None, 250, 250, 8)       32        
_________________________________________________________________
leaky_re_lu (LeakyReLU)      (None, 250, 250, 8)       0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 250, 250, 8)       576       
_________________________________________________________________
batch_normalization_v2_1 (Ba (None, 250, 250, 8)       32        
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 250, 250, 8)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 125, 125, 8)       576       
_________________________________________________________________
batch_normalization_v2_2 (Ba (None, 125, 125, 8)       32        
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 125, 125, 8)       0         
_________________________________________________________________
padder (Padder)              (None, 128, 128, 8)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 128, 128, 16)      1152      
_________________________________________________________________
batch_normalization_v2_3 (Ba (None, 128, 128, 16)      64        
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 128, 128, 16)      0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 128, 128, 16)      2304      
_________________________________________________________________
batch_normalization_v2_4 (Ba (None, 128, 128, 16)      64        
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 128, 128, 16)      0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 64, 64, 16)        2304      
_________________________________________________________________
batch_normalization_v2_5 (Ba (None, 64, 64, 16)        64        
_________________________________________________________________
leaky_re_lu_5 (LeakyReLU)    (None, 64, 64, 16)        0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 64, 64, 32)        4608      
_________________________________________________________________
batch_normalization_v2_6 (Ba (None, 64, 64, 32)        128       
_________________________________________________________________
leaky_re_lu_6 (LeakyReLU)    (None, 64, 64, 32)        0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 64, 64, 32)        9216      
_________________________________________________________________
batch_normalization_v2_7 (Ba (None, 64, 64, 32)        128       
_________________________________________________________________
leaky_re_lu_7 (LeakyReLU)    (None, 64, 64, 32)        0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 32, 32, 32)        9216      
_________________________________________________________________
batch_normalization_v2_8 (Ba (None, 32, 32, 32)        128       
_________________________________________________________________
leaky_re_lu_8 (LeakyReLU)    (None, 32, 32, 32)        0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 32, 32, 32)        9216      
_________________________________________________________________
batch_normalization_v2_9 (Ba (None, 32, 32, 32)        128       
_________________________________________________________________
leaky_re_lu_9 (LeakyReLU)    (None, 32, 32, 32)        0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 32, 32, 32)        9216      
_________________________________________________________________
batch_normalization_v2_10 (B (None, 32, 32, 32)        128       
_________________________________________________________________
leaky_re_lu_10 (LeakyReLU)   (None, 32, 32, 32)        0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 16, 16, 32)        9216      
_________________________________________________________________
batch_normalization_v2_11 (B (None, 16, 16, 32)        128       
_________________________________________________________________
leaky_re_lu_11 (LeakyReLU)   (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 16, 16, 32)        9216      
_________________________________________________________________
batch_normalization_v2_12 (B (None, 16, 16, 32)        128       
_________________________________________________________________
leaky_re_lu_12 (LeakyReLU)   (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 16, 16, 32)        9216      
_________________________________________________________________
batch_normalization_v2_13 (B (None, 16, 16, 32)        128       
_________________________________________________________________
leaky_re_lu_13 (LeakyReLU)   (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 8, 8, 32)          9216      
_________________________________________________________________
batch_normalization_v2_14 (B (None, 8, 8, 32)          128       
_________________________________________________________________
leaky_re_lu_14 (LeakyReLU)   (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 8, 8, 32)          9216      
_________________________________________________________________
batch_normalization_v2_15 (B (None, 8, 8, 32)          128       
_________________________________________________________________
leaky_re_lu_15 (LeakyReLU)   (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_16 (Conv2D)           (None, 8, 8, 32)          9216      
_________________________________________________________________
batch_normalization_v2_16 (B (None, 8, 8, 32)          128       
_________________________________________________________________
leaky_re_lu_16 (LeakyReLU)   (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_17 (Conv2D)           (None, 4, 4, 32)          9216      
_________________________________________________________________
batch_normalization_v2_17 (B (None, 4, 4, 32)          128       
_________________________________________________________________
leaky_re_lu_17 (LeakyReLU)   (None, 4, 4, 32)          0         
_________________________________________________________________
flatten (Flatten)            (None, 512)               0         
_________________________________________________________________
dense (Dense)                (None, 64)                32768     
_________________________________________________________________
batch_normalization_v2_18 (B (None, 64)                256       
_________________________________________________________________
leaky_re_lu_18 (LeakyReLU)   (None, 64)                0         
_________________________________________________________________
dropout (Dropout)            (None, 64)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 64        
=================================================================
Total params: 147,880
Trainable params: 146,840
Non-trainable params: 1,040
_________________________________________________________________

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "star_vae_colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "axdJ_iVYNwaS",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install -q tensorflow-gpu==2.0.0-alpha0\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4J9MAlDSHauX",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "path_csv = \"/content/drive/My Drive/labeled.csv\"\n",
        "path_labeled_images = \"/content/drive/My Drive/labeled\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mmdYI8fqN2B-",
        "outputId": "8a61c751-dff3-4835-e0c8-0df9983fee5a",
        "pycharm": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bvn4aGf9caM9",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "def extract_stars_28x28(image):\n",
        "\n",
        "  \"\"\" Extracts stars from an image\n",
        "    \n",
        "  Detects all stars within the given image, extracts them and centers them within patches of size 28x28 with \n",
        "  a black background.\n",
        "    \n",
        "    \n",
        "  Parameters\n",
        "  ----------\n",
        "  image : numpy.ndarray\n",
        "    The image from which the stars are extracted. The image is assumed to be grayscale.\n",
        "    \n",
        "    \n",
        "  Returns\n",
        "  -------\n",
        "  patches : list\n",
        "    A list containing the resulting 28x28 patches.\n",
        "        \n",
        "  \"\"\"\n",
        "  \n",
        "  _, image_binary = cv2.threshold(image, 1, 255, cv2.THRESH_BINARY)\n",
        "  \n",
        "  _, contours, _ = cv2.findContours(image_binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    \n",
        "    \n",
        "  # tuples (x, y, w, h)\n",
        "  bounding_rects = [cv2.boundingRect(c) for c in contours] \n",
        "  \n",
        "  bounding_rects_filtered = [r for r in bounding_rects \n",
        "                             if not(r[0] <= 0 or r[0] + r[2] >= 1000 or r[1] <= 0 or r[1] + r[3] >= 1000)]\n",
        "  \n",
        "  patches = []\n",
        "  \n",
        "  for r in bounding_rects_filtered:\n",
        "    \n",
        "    x = r[0]; y = r[1]; w = r[2]; h = r[3]\n",
        "    \n",
        "    if(w > 28 or h > 28):\n",
        "      continue\n",
        "    \n",
        "    star = image[y : y + h, x : x + w]\n",
        "    \n",
        "    if np.amax(star) < 30:\n",
        "      continue\n",
        "    \n",
        "    patch = np.zeros((28, 28), dtype=np.float32)\n",
        "    \n",
        "    padding_y = (28 - h) // 2\n",
        "    padding_x = (28 - w) // 2\n",
        "    \n",
        "    patch[padding_y : padding_y + h, padding_x : padding_x + w] = star\n",
        "    \n",
        "    patches.append(patch)\n",
        "  \n",
        "    \n",
        "  return patches\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DcKWiTSXN351",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "\n",
        "import cv2\n",
        "\n",
        "\n",
        "def load_labeled_images(path_csv, path_labeled_images):\n",
        "    \n",
        "    try:\n",
        "        csv_file = open(path_csv, \"r\")\n",
        "\n",
        "        list_id_label = [] # contains string tuples (id, label)\n",
        "\n",
        "        for line in csv_file:\n",
        "            if not \"Id,Actual\" in line:\n",
        "                line = line.rstrip() # remove trailing newline character            \n",
        "                list_id_label.append(line.split(\",\"))\n",
        "\n",
        "        list_id_label = sorted(list_id_label)\n",
        "\n",
        "        labels = np.zeros(len(list_id_label)) # contains labels\n",
        "\n",
        "        for idx, elem in enumerate(list_id_label):\n",
        "            labels[idx] = float(elem[1])\n",
        "\n",
        "        list_filenames = [] # contains filenames of images\n",
        "\n",
        "        for filename in os.listdir(path_labeled_images):\n",
        "            if filename.endswith(\".png\") and not filename.startswith(\".\"):\n",
        "                list_filenames.append(filename)\n",
        "\n",
        "        list_filenames = sorted(list_filenames)\n",
        "\n",
        "        assert len(labels) == len(list_filenames)\n",
        "\n",
        "        # i suppose an image needs approximately\n",
        "        # sizeof(np.float32) * 1 * 1000 * 1000 B of RAM\n",
        "\n",
        "        # a list works well in terms of performance\n",
        "        images = [] # images\n",
        "        mirror_images = [] # mirror images\n",
        "        \n",
        "                \n",
        "        for idx, filename in enumerate(list_filenames):\n",
        "            \n",
        "            if labels[idx] == 1.0: # include only images with label == 1.0\n",
        "      \n",
        "      \n",
        "                img = cv2.imread(os.path.join(path_labeled_images, filename), cv2.IMREAD_GRAYSCALE)\n",
        "    \n",
        "                patches = extract_stars_28x28(img)\n",
        "      \n",
        "      \n",
        "                for p in patches:\n",
        "          \n",
        "                  p = p.reshape((28, 28, 1))\n",
        "                  p = np.divide(p, 255.0)\n",
        "                  \n",
        "                  images.append(p)\n",
        "                  \n",
        "        \n",
        "        # conversion allows for batches to be extracted\n",
        "        return np.stack(images)\n",
        "\n",
        "    except Error:\n",
        "        print(\"error: failed to load dataset.\")\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m4Bphz-bN8Fn",
        "outputId": "c8d98461-8bfa-4661-91ac-301b8696a0ed",
        "pycharm": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "all_images = load_labeled_images(path_csv, path_labeled_images) # note: consider augment=True\n",
        "\n",
        "print(all_images.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6259, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C6dZpBoIN-UP",
        "outputId": "4fd8d0d6-4351-42cf-88f5-93f38e275587",
        "pycharm": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "\n",
        "num_images = len(all_images)\n",
        "print(num_images)\n",
        "\n",
        "frac_train = 0.9\n",
        "\n",
        "num_images_train = int(num_images * frac_train)\n",
        "num_images_test = num_images - num_images_train\n",
        "print(num_images_train)\n",
        "print(num_images_test)\n",
        "\n",
        "batch_size = 100 # HYPERPARAMETER !!!\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(all_images[:num_images_train, :, :, :]).shuffle(num_images_train).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(all_images[num_images_train:, :, :, :]).shuffle(num_images_test).batch(batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6259\n",
            "5633\n",
            "626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uslQWLlVIPxO",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "\n",
        "def get_num_parameters(model):\n",
        "  \n",
        "  total = 0\n",
        "  for var in model.trainable_weights:\n",
        "    total += tf.size(var)\n",
        "  \n",
        "  return total\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kyfqtY1iwbWp",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "\n",
        "class VAE(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self, latent_dim):\n",
        "    super(VAE, self).__init__()\n",
        "    \n",
        "    self.latent_dim = latent_dim\n",
        "    \n",
        "    self.inference_net = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(500, activation=None),\n",
        "            tf.keras.layers.BatchNormalization(momentum=0.99),\n",
        "            tf.keras.layers.ReLU(),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Dense(latent_dim + latent_dim) \n",
        "        ]\n",
        "    )\n",
        "        \n",
        "    self.generative_net = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
        "            tf.keras.layers.Dense(500, activation=None),\n",
        "            tf.keras.layers.BatchNormalization(momentum=0.99),\n",
        "            tf.keras.layers.ReLU(),\n",
        "            tf.keras.layers.Dense(28 * 28 * 1, activation=None),\n",
        "            tf.keras.layers.Reshape(target_shape=(28, 28, 1))\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    \n",
        "  def encode(self, x):\n",
        "    \n",
        "    mean, logvar = tf.split(self.inference_net(x), num_or_size_splits=2, axis=1)\n",
        "    \n",
        "    return mean, logvar\n",
        "\n",
        "  \n",
        "  def decode(self, z, apply_sigmoid=False):\n",
        "\n",
        "    logits = self.generative_net(z)\n",
        "    \n",
        "    if apply_sigmoid:\n",
        "      probs = tf.sigmoid(logits)\n",
        "      return probs\n",
        "\n",
        "    return logits\n",
        "  \n",
        "  \n",
        "  def reparameterize(self, mean, logvar):\n",
        "    \n",
        "    eps = tf.random.normal(shape=mean.shape)\n",
        "    \n",
        "    return eps * tf.exp(logvar * .5) + mean\n",
        "  \n",
        "  \n",
        "  def sample(self, eps=None):\n",
        "    if eps is None:\n",
        "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
        "      \n",
        "    return self.decode(eps)\n",
        "  \n",
        "  def save_ckpt_generative(self, path):\n",
        "    self.generative_net.save_weights(path)\n",
        "      \n",
        "  \n",
        "  def load_ckpt_generative(self, path):\n",
        "    self.generative_net.load_weights(path)\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kmJAnyMNzAv3",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "\n",
        "KL_div_mean = tf.keras.metrics.Mean('KL_div_mean', dtype=tf.float32)\n",
        "\n",
        "logpx_z_mean = tf.keras.metrics.Mean('logpx_z_mean', dtype=tf.float32)\n",
        "\n",
        "\n",
        "def KL_divergence(mean, logvar, raxis=1):\n",
        "  \n",
        "  return tf.reduce_sum(-0.5 * (1 + logvar - mean ** 2 - tf.exp(logvar)), axis=raxis)\n",
        "\n",
        "\n",
        "def compute_loss(model, x, annealing):\n",
        "  \n",
        "  mean, logvar = model.encode(x)\n",
        "  \n",
        "  z = model.reparameterize(mean, logvar)\n",
        "  \n",
        "  x_logit = model.decode(z)\n",
        "  \n",
        "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
        "  \n",
        "  KL_div = KL_divergence(mean, logvar)\n",
        "  \n",
        "  # NOTE: TensorBoard summaries\n",
        "  logpx_z_mean(logpx_z)\n",
        "  KL_div_mean(KL_div)\n",
        "  \n",
        "  # NOTE: negation causes ascent -> descent\n",
        "  # NOTE: reduce mean is expectation over batch of data\n",
        "  return -tf.reduce_mean(logpx_z - annealing * KL_div)\n",
        "\n",
        "\n",
        "# note: TensorFlow 2.0 optimization procedure\n",
        "def compute_gradients(model, x, annealing):\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    \n",
        "    loss = compute_loss(model, x, annealing)\n",
        "  \n",
        "  return tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "\n",
        "def apply_gradients(optimizer, gradients, variables):\n",
        "  \n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wz6NRwlS_Vxv",
        "outputId": "3640deda-2ded-49c3-a02d-e0b1cc5ca43f",
        "pycharm": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        }
      },
      "source": [
        "\n",
        "optimizer = tf.keras.optimizers.Adadelta(lr=1)\n",
        "\n",
        "epochs = 60\n",
        "\n",
        "latent_dim = 16 # NOTE: dimension of latent space (bad quality if too small)\n",
        "\n",
        "\n",
        "# instantiate model\n",
        "model = VAE(latent_dim) \n",
        "\n",
        "\n",
        "def compute_annealing(epoch, epochs):\n",
        "  \n",
        "  frac = float(epoch) / float(epochs)\n",
        "  \n",
        "  c1 = 20.0\n",
        "  c2 = 0.5\n",
        "  \n",
        "  return 1.0 / (1.0 + tf.exp(-c1 * (frac - c2)))\n",
        "\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    \n",
        "  annealing = compute_annealing(epoch, epochs)\n",
        "  \n",
        "  for x in train_dataset:\n",
        "    \n",
        "    gradients = compute_gradients(model, x, annealing)\n",
        "    apply_gradients(optimizer, gradients, model.trainable_variables)    \n",
        "    \n",
        "  if epoch % 5 == 0:  \n",
        "    print(\"Done with epoch {}.\".format(epoch))\n",
        "  \n",
        "    template = 'KL divergence (train) {}, Reconstr. error (train): {}'\n",
        "    print (template.format(KL_div_mean.result(), logpx_z_mean.result()))\n",
        "\n",
        "  # reset metrics\n",
        "  KL_div_mean.reset_states()\n",
        "  logpx_z_mean.reset_states()\n",
        "  \n",
        "  for x in test_dataset:\n",
        "    \n",
        "    compute_loss(model, x, annealing)\n",
        "    \n",
        "  if epoch % 5 == 0:  \n",
        "    print(\"done with epoch {}\".format(epoch))\n",
        "  \n",
        "    template = 'KL divergence (test) {}, Reconstr. error (test): {}'\n",
        "    print (template.format(KL_div_mean.result(), logpx_z_mean.result()))\n",
        "\n",
        "  # reset metrics\n",
        "  KL_div_mean.reset_states()\n",
        "  logpx_z_mean.reset_states()  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done with epoch 5.\n",
            "KL divergence (train) 76.57270050048828, Reconstr. error (train): -22.091337203979492\n",
            "done with epoch 5\n",
            "KL divergence (test) 77.08435821533203, Reconstr. error (test): -21.065641403198242\n",
            "Done with epoch 10.\n",
            "KL divergence (train) 69.5169677734375, Reconstr. error (train): -21.344833374023438\n",
            "done with epoch 10\n",
            "KL divergence (test) 66.31262969970703, Reconstr. error (test): -20.4805850982666\n",
            "Done with epoch 15.\n",
            "KL divergence (train) 43.84096908569336, Reconstr. error (train): -21.072134017944336\n",
            "done with epoch 15\n",
            "KL divergence (test) 41.35405349731445, Reconstr. error (test): -20.24997901916504\n",
            "Done with epoch 20.\n",
            "KL divergence (train) 17.53263282775879, Reconstr. error (train): -21.12388801574707\n",
            "done with epoch 20\n",
            "KL divergence (test) 17.172574996948242, Reconstr. error (test): -20.37071418762207\n",
            "Done with epoch 25.\n",
            "KL divergence (train) 5.969232559204102, Reconstr. error (train): -21.369613647460938\n",
            "done with epoch 25\n",
            "KL divergence (test) 5.56985330581665, Reconstr. error (test): -20.70892906188965\n",
            "Done with epoch 30.\n",
            "KL divergence (train) 2.5087039470672607, Reconstr. error (train): -21.84831428527832\n",
            "done with epoch 30\n",
            "KL divergence (test) 2.2025442123413086, Reconstr. error (test): -21.124652862548828\n",
            "Done with epoch 35.\n",
            "KL divergence (train) 1.7373931407928467, Reconstr. error (train): -21.986162185668945\n",
            "done with epoch 35\n",
            "KL divergence (test) 1.5122110843658447, Reconstr. error (test): -21.472890853881836\n",
            "Done with epoch 40.\n",
            "KL divergence (train) 1.57120943069458, Reconstr. error (train): -22.039886474609375\n",
            "done with epoch 40\n",
            "KL divergence (test) 1.4850857257843018, Reconstr. error (test): -21.403051376342773\n",
            "Done with epoch 45.\n",
            "KL divergence (train) 1.5050233602523804, Reconstr. error (train): -22.055633544921875\n",
            "done with epoch 45\n",
            "KL divergence (test) 1.3872593641281128, Reconstr. error (test): -21.43120002746582\n",
            "Done with epoch 50.\n",
            "KL divergence (train) 1.4776129722595215, Reconstr. error (train): -22.022022247314453\n",
            "done with epoch 50\n",
            "KL divergence (test) 1.419050931930542, Reconstr. error (test): -21.387508392333984\n",
            "Done with epoch 55.\n",
            "KL divergence (train) 1.4884124994277954, Reconstr. error (train): -22.015552520751953\n",
            "done with epoch 55\n",
            "KL divergence (test) 1.3680763244628906, Reconstr. error (test): -21.39995002746582\n",
            "Done with epoch 60.\n",
            "KL divergence (train) 1.4710733890533447, Reconstr. error (train): -21.994949340820312\n",
            "done with epoch 60\n",
            "KL divergence (test) 1.445953130722046, Reconstr. error (test): -21.331619262695312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LyaPQ3LhDswd",
        "outputId": "7bef5913-2812-4f8d-eca6-512ca05528dc",
        "pycharm": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "x = all_images[537, :, :, :].reshape((28, 28))\n",
        "\n",
        "x_img = Image.fromarray((x * 255).astype(np.uint8), mode='L')\n",
        "\n",
        "\n",
        "mean, logvar = model.encode(x.reshape(1, 28, 28, 1)) \n",
        "  \n",
        "z = model.reparameterize(mean, logvar)\n",
        "  \n",
        "x_logit = model.decode(z)\n",
        "\n",
        "x_logit_img = Image.fromarray((np.array(tf.sigmoid(x_logit)).reshape(28, 28) * 255).astype(np.uint8), mode='L')\n",
        "\n",
        "\n",
        "_, axarr = plt.subplots(1, 2)\n",
        "axarr[0].imshow(x_img, cmap='gray', vmin=0, vmax=255)\n",
        "axarr[1].imshow(x_logit_img, cmap='gray', vmin=0, vmax=255)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6a91551cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQBIUdABIgoIOAEn8PwNjmfp4GeebAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kTAYBorFEhhz",
        "outputId": "c2eb8e32-a388-47d3-ca84-f846ac513ff7",
        "pycharm": {},
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "\n",
        "samples_logits = model.sample()\n",
        "\n",
        "sample = Image.fromarray((np.array(tf.sigmoid(samples_logits[30, :, :, :])).reshape(28, 28) * 255).astype(np.uint8), \n",
        "                         mode='L')\n",
        "\n",
        "plt.imshow(sample, cmap='gray', vmin=0, vmax=255)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6a908c9c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8EtF/T9rOTTCfX2ufgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2e6ebJY_YEzi",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "\n",
        "from random import randint\n",
        "\n",
        "dir_gen_images = \"/content/drive/My Drive/generated_colab/\"\n",
        "\n",
        "\n",
        "def save_gen_images(dir_gen_images, n):\n",
        "  \n",
        "  for i in range(n):\n",
        "    \n",
        "    samples_logits = model.sample()\n",
        "    \n",
        "    j = randint(0, 99)\n",
        "\n",
        "    sample = Image.fromarray(\n",
        "        (np.array(tf.sigmoid(samples_logits[j, :, :, :])).reshape(28, 28) * 255).astype(np.uint8), mode='L')\n",
        "            \n",
        "    sample.save(dir_gen_images + \"image\" + str(i) + \".png\", \"png\")\n",
        "  \n",
        "  \n",
        "save_gen_images(dir_gen_images, 100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
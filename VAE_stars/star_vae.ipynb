{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STAR_autoencoder_v25.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "axdJ_iVYNwaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install -q tensorflow-gpu==2.0.0-alpha0\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J9MAlDSHauX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_csv = \"/content/drive/My Drive/labeled.csv\"\n",
        "path_labeled_images = \"/content/drive/My Drive/labeled\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmdYI8fqN2B-",
        "colab_type": "code",
        "outputId": "cbc9d97b-a0d1-4b82-8d9f-ded191908d17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvn4aGf9caM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_stars_28x28(image):\n",
        "\n",
        "  \"\"\" Extracts stars from an image\n",
        "    \n",
        "  Detects all stars within the given image, extracts them and centers them within patches of size 28x28 with \n",
        "  a black background.\n",
        "    \n",
        "    \n",
        "  Parameters\n",
        "  ----------\n",
        "  image : numpy.ndarray\n",
        "    The image from which the stars are extracted. The image is assumed to be grayscale.\n",
        "    \n",
        "    \n",
        "  Returns\n",
        "  -------\n",
        "  patches : list\n",
        "    A list containing the resulting 28x28 patches.\n",
        "        \n",
        "  \"\"\"\n",
        "  \n",
        "  _, image_binary = cv2.threshold(image, 1, 255, cv2.THRESH_BINARY)\n",
        "  \n",
        "  _, contours, _ = cv2.findContours(image_binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    \n",
        "    \n",
        "  # tuples (x, y, w, h)\n",
        "  bounding_rects = [cv2.boundingRect(c) for c in contours] \n",
        "  \n",
        "  bounding_rects_filtered = [r for r in bounding_rects \n",
        "                             if not(r[0] <= 0 or r[0] + r[2] >= 1000 or r[1] <= 0 or r[1] + r[3] >= 1000)]\n",
        "  \n",
        "  patches = []\n",
        "  \n",
        "  for r in bounding_rects_filtered:\n",
        "    \n",
        "    x = r[0]; y = r[1]; w = r[2]; h = r[3]\n",
        "    \n",
        "    if(w > 28 or h > 28):\n",
        "      continue\n",
        "    \n",
        "    star = image[y : y + h, x : x + w]\n",
        "    \n",
        "    if np.amax(star) < 30:\n",
        "      continue\n",
        "    \n",
        "    patch = np.zeros((28, 28), dtype=np.float32)\n",
        "    \n",
        "    padding_y = (28 - h) // 2\n",
        "    padding_x = (28 - w) // 2\n",
        "    \n",
        "    patch[padding_y : padding_y + h, padding_x : padding_x + w] = star\n",
        "    \n",
        "    patches.append(patch)\n",
        "  \n",
        "    \n",
        "  return patches\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcKWiTSXN351",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import cv2\n",
        "\n",
        "\n",
        "def load_labeled_images(path_csv, path_labeled_images):\n",
        "    \n",
        "    try:\n",
        "        csv_file = open(path_csv, \"r\")\n",
        "\n",
        "        list_id_label = [] # contains string tuples (id, label)\n",
        "\n",
        "        for line in csv_file:\n",
        "            if not \"Id,Actual\" in line:\n",
        "                line = line.rstrip() # remove trailing newline character            \n",
        "                list_id_label.append(line.split(\",\"))\n",
        "\n",
        "        list_id_label = sorted(list_id_label)\n",
        "\n",
        "        labels = np.zeros(len(list_id_label)) # contains labels\n",
        "\n",
        "        for idx, elem in enumerate(list_id_label):\n",
        "            labels[idx] = float(elem[1])\n",
        "\n",
        "        list_filenames = [] # contains filenames of images\n",
        "\n",
        "        for filename in os.listdir(path_labeled_images):\n",
        "            if filename.endswith(\".png\") and not filename.startswith(\".\"):\n",
        "                list_filenames.append(filename)\n",
        "\n",
        "        list_filenames = sorted(list_filenames)\n",
        "\n",
        "        assert len(labels) == len(list_filenames)\n",
        "\n",
        "        # i suppose an image needs approximately\n",
        "        # sizeof(np.float32) * 1 * 1000 * 1000 B of RAM\n",
        "\n",
        "        # a list works well in terms of performance\n",
        "        images = [] # images\n",
        "        mirror_images = [] # mirror images\n",
        "        \n",
        "                \n",
        "        for idx, filename in enumerate(list_filenames):\n",
        "            \n",
        "            if labels[idx] == 1.0: # include only images with label == 1.0\n",
        "      \n",
        "      \n",
        "                img = cv2.imread(os.path.join(path_labeled_images, filename), cv2.IMREAD_GRAYSCALE)\n",
        "    \n",
        "                patches = extract_stars_28x28(img)\n",
        "      \n",
        "      \n",
        "                for p in patches:\n",
        "          \n",
        "                  p = p.reshape((28, 28, 1))\n",
        "                  p = np.divide(p, 255.0)\n",
        "                  \n",
        "                  images.append(p)\n",
        "                  \n",
        "        \n",
        "        # conversion allows for batches to be extracted\n",
        "        return np.stack(images)\n",
        "\n",
        "    except Error:\n",
        "        print(\"error: failed to load dataset.\")\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4Bphz-bN8Fn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec9f85d7-29a0-4c52-db46-f9b547ffb68c"
      },
      "source": [
        "\n",
        "all_images = load_labeled_images(path_csv, path_labeled_images, augment=False) # note: consider augment=True\n",
        "\n",
        "print(all_images.shape)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6259, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6dZpBoIN-UP",
        "colab_type": "code",
        "outputId": "ec67f822-8aa1-42da-8ee6-6f1a057403ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "\n",
        "num_images = len(all_images)\n",
        "print(num_images)\n",
        "\n",
        "frac_train = 0.9\n",
        "\n",
        "num_images_train = int(num_images * frac_train)\n",
        "num_images_test = num_images - num_images_train\n",
        "print(num_images_train)\n",
        "print(num_images_test)\n",
        "\n",
        "batch_size = 100 # HYPERPARAMETER !!!\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(all_images[:num_images_train, :, :, :]).shuffle(num_images_train).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(all_images[num_images_train:, :, :, :]).shuffle(num_images_test).batch(batch_size)\n"
      ],
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6259\n",
            "5633\n",
            "626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uslQWLlVIPxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_num_parameters(model):\n",
        "  \n",
        "  total = 0\n",
        "  for var in model.trainable_weights:\n",
        "    total += tf.size(var)\n",
        "  \n",
        "  return total\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyfqtY1iwbWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class VAE(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self, latent_dim):\n",
        "    super(VAE, self).__init__()\n",
        "    \n",
        "    self.latent_dim = latent_dim\n",
        "    \n",
        "    self.inference_net = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(500, activation=None),\n",
        "            tf.keras.layers.ReLU(),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.BatchNormalization(momentum=0.99),\n",
        "            tf.keras.layers.Dense(latent_dim + latent_dim) \n",
        "        ]\n",
        "    )\n",
        "        \n",
        "    self.generative_net = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
        "            tf.keras.layers.Dense(500, activation=None),\n",
        "            tf.keras.layers.ReLU(),\n",
        "            tf.keras.layers.BatchNormalization(momentum=0.99),\n",
        "            tf.keras.layers.Dense(28 * 28 * 1, activation=None),\n",
        "            tf.keras.layers.Reshape(target_shape=(28, 28, 1))\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    \n",
        "  def encode(self, x):\n",
        "    \n",
        "    mean, logvar = tf.split(self.inference_net(x), num_or_size_splits=2, axis=1)\n",
        "    \n",
        "    return mean, logvar\n",
        "\n",
        "  \n",
        "  def decode(self, z, apply_sigmoid=False):\n",
        "\n",
        "    logits = self.generative_net(z)\n",
        "    \n",
        "    if apply_sigmoid:\n",
        "      probs = tf.sigmoid(logits)\n",
        "      return probs\n",
        "\n",
        "    return logits\n",
        "  \n",
        "  \n",
        "  def reparameterize(self, mean, logvar):\n",
        "    \n",
        "    eps = tf.random.normal(shape=mean.shape)\n",
        "    \n",
        "    return eps * tf.exp(logvar * .5) + mean\n",
        "  \n",
        "  \n",
        "  def sample(self, eps=None):\n",
        "    if eps is None:\n",
        "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
        "      \n",
        "    return self.decode(eps)\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmJAnyMNzAv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "KL_div_mean = tf.keras.metrics.Mean('KL_div_mean', dtype=tf.float32)\n",
        "\n",
        "logpx_z_mean = tf.keras.metrics.Mean('logpx_z_mean', dtype=tf.float32)\n",
        "\n",
        "\n",
        "def KL_divergence(mean, logvar, raxis=1):\n",
        "  \n",
        "  return tf.reduce_sum(-0.5 * (1 + logvar - mean ** 2 - tf.exp(logvar)), axis=raxis)\n",
        "\n",
        "\n",
        "def compute_loss(model, x, annealing):\n",
        "  \n",
        "  mean, logvar = model.encode(x)\n",
        "  \n",
        "  z = model.reparameterize(mean, logvar)\n",
        "  \n",
        "  x_logit = model.decode(z)\n",
        "  \n",
        "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
        "  \n",
        "  KL_div = KL_divergence(mean, logvar)\n",
        "  \n",
        "  # NOTE: TensorBoard summaries\n",
        "  logpx_z_mean(logpx_z)\n",
        "  KL_div_mean(KL_div)\n",
        "  \n",
        "  # NOTE: negation causes ascent -> descent\n",
        "  # NOTE: reduce mean is expectation over batch of data\n",
        "  return -tf.reduce_mean(logpx_z - annealing * KL_div)\n",
        "\n",
        "\n",
        "# note: TensorFlow 2.0 optimization procedure\n",
        "def compute_gradients(model, x, annealing):\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    \n",
        "    loss = compute_loss(model, x, annealing)\n",
        "  \n",
        "  return tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "\n",
        "def apply_gradients(optimizer, gradients, variables):\n",
        "  \n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz6NRwlS_Vxv",
        "colab_type": "code",
        "outputId": "3c4dffb0-c858-46fe-a9ac-62e3c41d7cc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "\n",
        "optimizer = tf.keras.optimizers.Adadelta(lr=1)\n",
        "\n",
        "epochs = 40\n",
        "\n",
        "latent_dim = 16 # NOTE: dimension of latent space (bad quality if too small)\n",
        "\n",
        "\n",
        "# instantiate model\n",
        "model = VAE(latent_dim) \n",
        "\n",
        "\n",
        "def compute_annealing(epoch, epochs):\n",
        "  \n",
        "  frac = float(epoch) / float(epochs)\n",
        "  \n",
        "  c1 = 20.0\n",
        "  c2 = 0.5\n",
        "  \n",
        "  return 1.0 / (1.0 + tf.exp(-c1 * (frac - c2)))\n",
        "\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    \n",
        "  annealing = compute_annealing(epoch, epochs)\n",
        "  \n",
        "  for x in train_dataset:\n",
        "    \n",
        "    gradients = compute_gradients(model, x, annealing)\n",
        "    apply_gradients(optimizer, gradients, model.trainable_variables)    \n",
        "    \n",
        "  if epoch % 5 == 0:  \n",
        "    print(\"Done with epoch {}.\".format(epoch))\n",
        "  \n",
        "    template = 'KL divergence (train) {}, Reconstr. error (train): {}'\n",
        "    print (template.format(KL_div_mean.result(), logpx_z_mean.result()))\n",
        "\n",
        "  # reset metrics\n",
        "  KL_div_mean.reset_states()\n",
        "  logpx_z_mean.reset_states()\n",
        "  \n",
        "  for x in test_dataset:\n",
        "    \n",
        "    compute_loss(model, x, annealing)\n",
        "    \n",
        "  if epoch % 5 == 0:  \n",
        "    print(\"done with epoch {}\".format(epoch))\n",
        "  \n",
        "    template = 'KL divergence (test) {}, Reconstr. error (test): {}'\n",
        "    print (template.format(KL_div_mean.result(), logpx_z_mean.result()))\n",
        "\n",
        "  # reset metrics\n",
        "  KL_div_mean.reset_states()\n",
        "  logpx_z_mean.reset_states()  \n",
        "\n"
      ],
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done with epoch 5.\n",
            "KL divergence (train) 79.28279876708984, Reconstr. error (train): -21.968503952026367\n",
            "done with epoch 5\n",
            "KL divergence (test) 69.49922943115234, Reconstr. error (test): -22.092529296875\n",
            "Done with epoch 10.\n",
            "KL divergence (train) 48.80472946166992, Reconstr. error (train): -21.460693359375\n",
            "done with epoch 10\n",
            "KL divergence (test) 40.15911865234375, Reconstr. error (test): -21.14863395690918\n",
            "Done with epoch 15.\n",
            "KL divergence (train) 12.092446327209473, Reconstr. error (train): -21.473337173461914\n",
            "done with epoch 15\n",
            "KL divergence (test) 10.516654968261719, Reconstr. error (test): -21.444307327270508\n",
            "Done with epoch 20.\n",
            "KL divergence (train) 2.5313892364501953, Reconstr. error (train): -21.961265563964844\n",
            "done with epoch 20\n",
            "KL divergence (test) 2.216724395751953, Reconstr. error (test): -21.691022872924805\n",
            "Done with epoch 25.\n",
            "KL divergence (train) 1.649268388748169, Reconstr. error (train): -22.183551788330078\n",
            "done with epoch 25\n",
            "KL divergence (test) 1.4655752182006836, Reconstr. error (test): -21.926931381225586\n",
            "Done with epoch 30.\n",
            "KL divergence (train) 1.5213068723678589, Reconstr. error (train): -22.137535095214844\n",
            "done with epoch 30\n",
            "KL divergence (test) 1.3913533687591553, Reconstr. error (test): -21.545930862426758\n",
            "Done with epoch 35.\n",
            "KL divergence (train) 1.4881983995437622, Reconstr. error (train): -22.150354385375977\n",
            "done with epoch 35\n",
            "KL divergence (test) 1.4751638174057007, Reconstr. error (test): -21.74692153930664\n",
            "Done with epoch 40.\n",
            "KL divergence (train) 1.4662988185882568, Reconstr. error (train): -22.099964141845703\n",
            "done with epoch 40\n",
            "KL divergence (test) 1.4301304817199707, Reconstr. error (test): -21.346466064453125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyaPQ3LhDswd",
        "colab_type": "code",
        "outputId": "66466826-72a6-46c1-9249-3b156510cf82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "\n",
        "x = all_images[537, :, :, :].reshape((28, 28))\n",
        "\n",
        "x_img = Image.fromarray((x * 255).astype(np.uint8), mode='L')\n",
        "\n",
        "\n",
        "mean, logvar = model.encode(x.reshape(1, 28, 28, 1)) \n",
        "  \n",
        "z = model.reparameterize(mean, logvar)\n",
        "  \n",
        "x_logit = model.decode(z)\n",
        "\n",
        "x_logit_img = Image.fromarray((np.array(tf.sigmoid(x_logit)).reshape(28, 28) * 255).astype(np.uint8), mode='L')\n",
        "\n",
        "\n",
        "_, axarr = plt.subplots(1, 2)\n",
        "axarr[0].imshow(x_img, cmap='gray', vmin=0, vmax=255)\n",
        "axarr[1].imshow(x_logit_img, cmap='gray', vmin=0, vmax=255)\n"
      ],
      "execution_count": 426,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1262f36588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 426
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTAYBorFEhhz",
        "colab_type": "code",
        "outputId": "0631ab64-13cf-45fd-b64c-fe7c2a2ed510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "\n",
        "samples_logits = model.sample()\n",
        "\n",
        "sample = Image.fromarray((np.array(tf.sigmoid(samples_logits[30, :, :, :])).reshape(28, 28) * 255).astype(np.uint8), \n",
        "                         mode='L')\n",
        "\n",
        "plt.imshow(sample, cmap='gray', vmin=0, vmax=255)\n"
      ],
      "execution_count": 425,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1262fb20f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 425
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwJ5N/8CpAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e6ebJY_YEzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from random import randint\n",
        "\n",
        "dir_gen_images = \"/content/drive/My Drive/generated/\"\n",
        "\n",
        "\n",
        "def save_gen_images(dir_gen_images, n):\n",
        "  \n",
        "  for i in range(n):\n",
        "    \n",
        "    samples_logits = model.sample()\n",
        "    \n",
        "    j = randint(0, 99)\n",
        "\n",
        "    sample = Image.fromarray(\n",
        "        (np.array(tf.sigmoid(samples_logits[j, :, :, :])).reshape(28, 28) * 255).astype(np.uint8), mode='L')\n",
        "            \n",
        "    sample.save(dir_gen_images + \"image\" + str(i) + \".png\", \"png\")\n",
        "  \n",
        "  \n",
        "save_gen_images(dir_gen_images, 100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}